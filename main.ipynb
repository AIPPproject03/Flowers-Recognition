{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmdbTvxATnQU",
        "outputId": "c1f3711d-e29b-4221-a54f-2ed3d4c51887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4317 files belonging to 5 classes.\n",
            "Using 3022 files for training.\n",
            "Found 4317 files belonging to 5 classes.\n",
            "Using 1295 files for validation.\n",
            "\n",
            ">>> Training tahap 1 (Feature Extraction)...\n",
            "Epoch 1/5\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 1s/step - accuracy: 0.4723 - loss: 1.3131 - val_accuracy: 0.8355 - val_loss: 0.5276\n",
            "Epoch 2/5\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.7861 - loss: 0.5895 - val_accuracy: 0.8695 - val_loss: 0.4044\n",
            "Epoch 3/5\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 2s/step - accuracy: 0.8279 - loss: 0.4894 - val_accuracy: 0.8865 - val_loss: 0.3613\n",
            "Epoch 4/5\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - accuracy: 0.8583 - loss: 0.4186 - val_accuracy: 0.8950 - val_loss: 0.3315\n",
            "Epoch 5/5\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2s/step - accuracy: 0.8738 - loss: 0.3733 - val_accuracy: 0.8981 - val_loss: 0.3206\n",
            "\n",
            ">>> Fine-tuning (Unfreeze layer akhir)...\n",
            "Epoch 1/5\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 2s/step - accuracy: 0.8559 - loss: 0.4234 - val_accuracy: 0.8927 - val_loss: 0.3192\n",
            "Epoch 2/5\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 1s/step - accuracy: 0.8562 - loss: 0.3776 - val_accuracy: 0.8911 - val_loss: 0.3207\n",
            "Epoch 3/5\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 2s/step - accuracy: 0.8651 - loss: 0.3722 - val_accuracy: 0.8934 - val_loss: 0.3205\n",
            "Epoch 4/5\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 2s/step - accuracy: 0.8722 - loss: 0.3628 - val_accuracy: 0.8919 - val_loss: 0.3189\n",
            "Epoch 5/5\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 2s/step - accuracy: 0.8700 - loss: 0.3809 - val_accuracy: 0.8934 - val_loss: 0.3164\n",
            "\n",
            ">>> Evaluasi model:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       daisy       0.91      0.89      0.90       214\n",
            "   dandelion       0.92      0.91      0.92       296\n",
            "        rose       0.85      0.86      0.85       257\n",
            "   sunflower       0.93      0.94      0.93       218\n",
            "       tulip       0.87      0.87      0.87       310\n",
            "\n",
            "    accuracy                           0.89      1295\n",
            "   macro avg       0.90      0.89      0.90      1295\n",
            "weighted avg       0.89      0.89      0.89      1295\n",
            "\n",
            "\n",
            ">>> Model disimpan ke: flower_classifier_densenet.h5\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ==================== 1. Load Dataset ====================\n",
        "dataset_path = 'flowers'  # Ganti sesuai lokasi folder\n",
        "batch_size = 32\n",
        "img_size = (224, 224)\n",
        "\n",
        "train_ds = image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    validation_split=0.3,\n",
        "    subset=\"training\",\n",
        "    seed=123,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = image_dataset_from_directory(\n",
        "    dataset_path,\n",
        "    validation_split=0.3,\n",
        "    subset=\"validation\",\n",
        "    seed=123,\n",
        "    image_size=img_size,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "# ==================== 2. Augmentasi & Preprocessing ====================\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "])\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
        "train_ds = train_ds.map(lambda x, y: (preprocess_input(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (preprocess_input(x), y))\n",
        "\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# ==================== 3. Feature Extraction ====================\n",
        "base_model = DenseNet121(weights=\"imagenet\", include_top=False, input_shape=img_size + (3,))\n",
        "base_model.trainable = False  # Freeze semua layer\n",
        "\n",
        "inputs = tf.keras.Input(shape=img_size + (3,))\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "outputs = layers.Dense(len(class_names), activation='softmax')(x)\n",
        "\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# ==================== 4. Training Awal (Feature Extraction) ====================\n",
        "print(\"\\n>>> Training tahap 1 (Feature Extraction)...\")\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=5)\n",
        "\n",
        "# ==================== 5. Fine Tuning ====================\n",
        "print(\"\\n>>> Fine-tuning (Unfreeze layer akhir)...\")\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:-20]:  # Fine-tune 20 layer terakhir\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Optional: EarlyStopping\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train ulang\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=5, callbacks=[early_stop])\n",
        "\n",
        "# ==================== 6. Evaluasi ====================\n",
        "print(\"\\n>>> Evaluasi model:\")\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for images, labels in val_ds:\n",
        "    preds = model.predict(images)\n",
        "    y_true.extend(labels.numpy())\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# ==================== 7. Simpan Model ====================\n",
        "model.save(\"models/flower_classifier_densenet.h5\")\n",
        "print(\"\\n>>> Model disimpan ke: flower_classifier_densenet.h5\")\n",
        "\n",
        "# ==================== 8. Fungsi Prediksi Gambar Baru ====================\n",
        "def predict_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=img_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    preds = model.predict(img_array)\n",
        "    class_idx = np.argmax(preds)\n",
        "    confidence = np.max(preds)\n",
        "\n",
        "    plt.imshow(img.astype(\"uint8\"))\n",
        "    plt.title(f\"Prediksi: {class_names[class_idx]} ({confidence:.2%})\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vek9-IjWunI"
      },
      "source": [
        "| Tahapan Konsep Slide                          | Kode Python                                           | Penjelasan                                                                                        |\n",
        "| --------------------------------------------- | ----------------------------------------------------- | ------------------------------------------------------------------------------------------------- |\n",
        "| **1. Load Dataset**                           | `image_dataset_from_directory(...)`                   | Sesuai slide, kita mempersiapkan data baru (tugas baru) yang berbeda dari pretrain                |\n",
        "| **2. Preprocessing & Augmentasi**             | `preprocess_input`, `data_augmentation`               | Mempersiapkan input gambar agar sesuai standar DenseNet121 + augmentasi untuk memperkuat model    |\n",
        "| **3. Transfer Learning – Feature Extraction** | `base_model.trainable = False`                        | Sesuai slide \"Feature Reuse\" → semua layer pre-trained dibekukan                                  |\n",
        "| **4. Tambah Classifier Baru**                 | `GlobalAveragePooling2D`, `Dense(...)`                | Ganti layer klasifikasi sesuai jumlah kelas (5 bunga)                                             |\n",
        "| **5. Training Awal (Feature Extraction)**     | `model.fit(..., epochs=5)`                            | Melatih classifier baru saja, pretrained model dibekukan                                          |\n",
        "| **6. Transfer Learning – Fine Tuning**        | `base_model.trainable = True`, `unfreeze layer[-20:]` | Sesuai slide \"Fine Tuning\" → unfreeze sebagian layer akhir dan retrain dengan learning rate kecil |\n",
        "| **7. Evaluasi Model**                         | `classification_report(...)`                          | Mengukur akurasi, presisi, dan recall – sesuai permintaan tugas                                   |\n",
        "| **8. Simpan Model**                           | `model.save(...)`                                     | Untuk reuse model nanti (inference atau deploy)                                                   |\n",
        "| **9. Prediksi Gambar Baru (Demo/Video)**      | `predict_image(...)`                                  | Fungsi tambahan untuk presentasi dan validasi model                                               |\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "qOgGt1UMTrGi"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
